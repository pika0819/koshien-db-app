import streamlit as st
from google.cloud import bigquery
from google.api_core.exceptions import NotFound
import pandas as pd
import google.oauth2.service_account

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ç”²å­åœ’DB", layout="wide", page_icon="âš¾")
st.title("âš¾ï¸ ç”²å­åœ’DB")

# ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´
st.markdown("""
<style>
    .pro-box {
        padding: 15px; border-radius: 8px; background-color: #2e8b57; color: white;
        margin-bottom: 10px; font-weight: bold; border: 1px solid #1e5b38;
    }
    .japan-box {
        padding: 15px; border-radius: 8px; background-color: #DAA520; color: white;
        margin-bottom: 10px; font-weight: bold; border: 1px solid #B8860B;
    }
    .profile-meta {
        color: #666; font-size: 0.9em; margin-bottom: 15px;
    }
    /* ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
    div[data-testid="stLinkButton"] p { font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- 1. BigQueryæ¥ç¶šè¨­å®š ---
@st.cache_resource
def get_bq_client():
    try:
        scopes = [
            "https://www.googleapis.com/auth/bigquery",
            "https://www.googleapis.com/auth/drive",
            "https://www.googleapis.com/auth/spreadsheets",
        ]
        credentials = google.oauth2.service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=scopes
        )
        return bigquery.Client(credentials=credentials, project=credentials.project_id)
    except Exception as e:
        st.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

client = get_bq_client()
PROJECT_ID = st.secrets["gcp_service_account"]["project_id"]
RAW_DATASET_ID = "koshien_data"
APP_DATASET_ID = "koshien_app"

# --- 2. ãƒ‡ãƒ¼ã‚¿åŒæœŸæ©Ÿèƒ½ ---
def sync_data():
    status_text = st.empty()
    bar = st.progress(0)
    
    dataset_ref = client.dataset(APP_DATASET_ID)
    try:
        client.get_dataset(dataset_ref)
    except NotFound:
        status_text.text(f"åˆæœŸè¨­å®šä¸­: {APP_DATASET_ID} ã‚’ä½œæˆ...")
        dataset = bigquery.Dataset(dataset_ref)
        dataset.location = "US"
        client.create_dataset(dataset)

    # åŒæœŸå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«
    tables = ["m_tournament", "m_school", "m_player", "t_results", "t_scores", "m_region"]
    
    for i, table_name in enumerate(tables):
        status_text.text(f"åŒæœŸä¸­: {table_name}...")
        query = f"""
        CREATE OR REPLACE TABLE `{PROJECT_ID}.{APP_DATASET_ID}.{table_name}` AS
        SELECT * FROM `{PROJECT_ID}.{RAW_DATASET_ID}.{table_name}`
        """
        job = client.query(query)
        job.result()
        bar.progress((i + 1) / len(tables))

    status_text.text("å®Œäº†ï¼ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")
    st.success("ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†")
    st.cache_data.clear()
    st.rerun()

# --- 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ•´å½¢é–¢æ•° ---

def clean_and_rename(df):
    if df.empty: return df
    drop_cols = ['School_ID', 'ID', 'MatchLink', 'Tournament_ID', 'Region_ID']
    cols = [c for c in df.columns if c not in drop_cols]
    df = df[cols]
    rename_map = {
        'Year': 'å¹´åº¦', 'Season': 'å­£ç¯€', 'Tournament': 'å¤§ä¼šå',
        'School_Name_Now': 'ç¾åœ¨æ ¡å', 'School_Name_Then': 'å½“æ™‚ã®æ ¡å',
        'District': 'åœ°åŒº', 'Prefecture': 'éƒ½é“åºœçœŒ',
        'Uniform_Number': 'èƒŒç•ªå·', 'Name': 'æ°å', 'Position': 'å®ˆå‚™',
        'Grade': 'å­¦å¹´', 'Captain': 'ä¸»å°†', 'Pro_Team': 'ãƒ—ãƒ­å…¥å›£', 
        'Draft_Year': 'ãƒ‰ãƒ©ãƒ•ãƒˆå¹´', 'Draft_Rank': 'é †ä½', 'Throw_Bat': 'æŠ•æ‰“',
        'Birth_Date': 'ç”Ÿå¹´æœˆæ—¥', 'Generation': 'ä¸–ä»£', 
        # æ–°ã—ã„åˆ—å
        'U12': 'U12ä»£è¡¨', 'U15': 'U15ä»£è¡¨', 'U18': 'U18ä»£è¡¨', 'U22': 'U22ä»£è¡¨', 'JAPAN': 'ä¾ã‚¸ãƒ£ãƒ‘ãƒ³',
        'Rank': 'æˆç¸¾', 'Win_Loss': 'å‹æ•—', 'Score': 'ã‚¹ã‚³ã‚¢', 'Opponent': 'å¯¾æˆ¦æ ¡',
        'Round': 'å›æˆ¦', 'Notes': 'å‚™è€ƒ', 'History_Label': 'å‡ºå ´å›æ•°',
        'Year_Link': 'å¹´åº¦ãƒªãƒ³ã‚¯', 'History_Link': 'æ­´å²é¤¨', 'Virtual_Koshien_Link': 'ãƒãƒ¼ãƒãƒ£ãƒ«'
    }
    return df.rename(columns=rename_map)

# A. å¤§ä¼šæ¤œç´¢
@st.cache_data(ttl=3600)
def get_tournaments():
    try:
        sql = "SELECT * FROM `{}.{}.m_tournament` ORDER BY SAFE_CAST(Year AS INT64) DESC, Season DESC".format(PROJECT_ID, APP_DATASET_ID)
        return client.query(sql).to_dataframe().drop_duplicates()
    except: return pd.DataFrame()

@st.cache_data(ttl=3600)
def load_tournament_details(year, season):
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("year", "STRING", str(year)),
            bigquery.ScalarQueryParameter("season", "STRING", str(season))
        ]
    )
    sql_list = """
    SELECT tr.District, tr.School_Name_Then, s.School_Name_Now, tr.History_Label, tr.Rank, tr.School_ID
    FROM `{0}.{1}.t_results` AS tr
    LEFT JOIN `{0}.{1}.m_school` AS s ON tr.School_ID = s.School_ID
    WHERE tr.Year = @year AND tr.Season = @season
    """.format(PROJECT_ID, APP_DATASET_ID)
    
    sql_scores = "SELECT * FROM `{0}.{1}.t_scores` WHERE Year = @year AND Season = @season".format(PROJECT_ID, APP_DATASET_ID)
    sql_members = "SELECT * FROM `{0}.{1}.m_player` WHERE Year = @year AND Season = @season".format(PROJECT_ID, APP_DATASET_ID)

    return {
        "list": client.query(sql_list, job_config=job_config).to_dataframe().drop_duplicates(),
        "scores": client.query(sql_scores, job_config=job_config).to_dataframe().drop_duplicates(),
        "members": client.query(sql_members, job_config=job_config).to_dataframe().drop_duplicates()
    }

# B. é¸æ‰‹æ¤œç´¢
@st.cache_data(ttl=3600)
def search_players_list(query_text):
    sql = """
    SELECT DISTINCT Name, School_Name_Then, MAX(Year) as Last_Year
    FROM `{0}.{1}.m_player`
    WHERE Name LIKE @q
    GROUP BY Name, School_Name_Then
    ORDER BY Last_Year DESC
    LIMIT 50
    """.format(PROJECT_ID, APP_DATASET_ID)
    job_config = bigquery.QueryJobConfig(
        query_parameters=[bigquery.ScalarQueryParameter("q", "STRING", f"%{query_text}%")]
    )
    return client.query(sql, job_config=job_config).to_dataframe()

@st.cache_data(ttl=3600)
def get_player_detail(name, school_then):
    sql = """
    SELECT p.*, tr.Rank as Tournament_Rank
    FROM `{0}.{1}.m_player` AS p
    LEFT JOIN `{0}.{1}.t_results` AS tr 
      ON p.School_ID = tr.School_ID AND p.Year = tr.Year AND p.Season = tr.Season
    WHERE p.Name = @name AND p.School_Name_Then = @school_then
    ORDER BY SAFE_CAST(p.Year AS INT64), p.Season
    """.format(PROJECT_ID, APP_DATASET_ID)
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("name", "STRING", name),
            bigquery.ScalarQueryParameter("school_then", "STRING", school_then)
        ]
    )
    return client.query(sql, job_config=job_config).to_dataframe()

# C. é«˜æ ¡æ¤œç´¢
@st.cache_data(ttl=3600)
def search_schools(query_text):
    sql = """
    SELECT DISTINCT School_ID, School_Name_Now, Prefecture, School_Name_Then
    FROM `{0}.{1}.m_school`
    WHERE School_Name_Now LIKE @q OR School_Name_Then LIKE @q
    LIMIT 50
    """.format(PROJECT_ID, APP_DATASET_ID)
    job_config = bigquery.QueryJobConfig(
        query_parameters=[bigquery.ScalarQueryParameter("q", "STRING", f"%{query_text}%")]
    )
    return client.query(sql, job_config=job_config).to_dataframe()

@st.cache_data(ttl=3600)
def get_school_history_all(school_id):
    sql = """
    SELECT Year, Season, Tournament, School_Name_Then, Rank
    FROM `{0}.{1}.t_results`
    WHERE School_ID = @school_id
    ORDER BY SAFE_CAST(Year AS INT64) DESC
    """.format(PROJECT_ID, APP_DATASET_ID)
    job_config = bigquery.QueryJobConfig(
        query_parameters=[bigquery.ScalarQueryParameter("school_id", "STRING", school_id)]
    )
    return client.query(sql, job_config=job_config).to_dataframe()


# --- 4. UIæ§‹ç¯‰ ---

st.sidebar.header("ğŸ” æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰")
search_mode = st.sidebar.radio("", ["ğŸŸ å¤§ä¼šã‹ã‚‰æ¢ã™", "ğŸ‘¤ é¸æ‰‹åã‹ã‚‰æ¢ã™", "ğŸ« é«˜æ ¡åã‹ã‚‰æ¢ã™"])

st.sidebar.markdown("---")
st.sidebar.caption("â€»ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ—ã‚’è¿½åŠ ãƒ»å¤‰æ›´ã—ãŸå ´åˆã¯ã€å¿…ãšä¸‹ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚")
if st.sidebar.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æœ€æ–°ã«æ›´æ–°"):
    with st.spinner("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸä¸­..."):
        sync_data()

# === ãƒ¢ãƒ¼ãƒ‰1: å¤§ä¼šæ¤œç´¢ ===
if search_mode == "ğŸŸ å¤§ä¼šã‹ã‚‰æ¢ã™":
    df_tourney = get_tournaments()
    if df_tourney.empty:
        st.info("å·¦ä¸‹ã®æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        st.stop()
        
    df_tourney = df_tourney.fillna('')
    tourney_map = {}
    
    # é¸æŠè‚¢ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    for _, row in df_tourney.iterrows():
        y, s, t = row.get('Year', ''), row.get('Season', ''), row.get('Tournament', '')
        label = f"{y} {s} - {t}"
        # 3ç¨®é¡ã®ãƒªãƒ³ã‚¯ã‚’è¾æ›¸ã«ä¿æŒ
        tourney_map[label] = {
            "year": y, "season": s, "name": t,
            "link_year": row.get('Year_Link', ''),
            "link_hist": row.get('History_Link', ''),
            "link_virt": row.get('Virtual_Koshien_Link', '')
        }
    
    selected_label = st.sidebar.selectbox("å¤§ä¼šã‚’é¸æŠ", list(tourney_map.keys()))
    sel = tourney_map[selected_label]
    
    # === 3ã¤ã®ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ã‚’ä¸¦ã¹ã¦è¡¨ç¤º ===
    st.header(f"{selected_label}")
    
    # ãƒªãƒ³ã‚¯ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    links_to_show = []
    if sel["link_year"] and sel["link_year"].startswith("http"):
        links_to_show.append(("ğŸ”— å¤§ä¼šæƒ…å ± (ä¸»å‚¬è€…)", sel["link_year"]))
    if sel["link_hist"] and sel["link_hist"].startswith("http"):
        links_to_show.append(("ğŸ› ç”²å­åœ’æ­´å²é¤¨", sel["link_hist"]))
    if sel["link_virt"] and sel["link_virt"].startswith("http"):
        links_to_show.append(("ğŸ“º ãƒãƒ¼ãƒãƒ£ãƒ«é«˜æ ¡é‡çƒ", sel["link_virt"]))
    
    if links_to_show:
        cols = st.columns(len(links_to_show))
        for i, (text, url) in enumerate(links_to_show):
            cols[i].link_button(text, url)
    
    st.divider()

    with st.spinner("ãƒ‡ãƒ¼ã‚¿å±•é–‹ä¸­..."):
        data = load_tournament_details(sel["year"], sel["season"])
        df_list = data["list"]

    if not df_list.empty:
        st.dataframe(clean_and_rename(df_list), use_container_width=True, hide_index=True)
        st.subheader("ğŸ”½ è©³ç´°ãƒ‡ãƒ¼ã‚¿é–²è¦§")
        
        school_opts = dict(zip(df_list['School_Name_Then'], df_list['School_ID']))
        selected_school = st.selectbox("é«˜æ ¡ã‚’é¸æŠã—ã¦ãã ã•ã„", list(school_opts.keys()))
        
        if selected_school:
            sid = school_opts[selected_school]
            my_scores = data["scores"][data["scores"]['School_ID'] == sid]
            my_members = data["members"][data["members"]['School_ID'] == sid]
            
            t1, t2 = st.tabs(["âš¾ï¸ æˆ¦ç¸¾ãƒ»ã‚¹ã‚³ã‚¢", "ğŸ‘¥ ç™»éŒ²ãƒ¡ãƒ³ãƒãƒ¼"])
            with t1:
                if not my_scores.empty:
                    cols = ['Round', 'Opponent', 'Win_Loss', 'Score', 'Notes']
                    existing_cols = [c for c in cols if c in my_scores.columns]
                    st.dataframe(clean_and_rename(my_scores[existing_cols]), use_container_width=True, hide_index=True)
                else: st.info("æˆ¦ç¸¾ãƒ‡ãƒ¼ã‚¿ãªã—")
            with t2:
                if not my_members.empty:
                    if 'Uniform_Number' in my_members.columns:
                        try:
                            my_members['Unum'] = pd.to_numeric(my_members['Uniform_Number'], errors='coerce')
                            my_members = my_members.sort_values('Unum').drop(columns=['Unum'])
                        except: pass
                    target_cols = ['Uniform_Number', 'Position', 'Name', 'Grade', 'Captain', 'Pro_Team']
                    exist_target = [c for c in target_cols if c in my_members.columns]
                    st.dataframe(clean_and_rename(my_members[exist_target]), use_container_width=True, hide_index=True)
                else: st.info("ãƒ¡ãƒ³ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ãªã—")

# === ãƒ¢ãƒ¼ãƒ‰2: é¸æ‰‹æ¤œç´¢ ===
elif search_mode == "ğŸ‘¤ é¸æ‰‹åã‹ã‚‰æ¢ã™":
    st.subheader("ğŸ‘¤ é¸æ‰‹æ¤œç´¢")
    q = st.text_input("é¸æ‰‹åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šæ¾å‚å¤§è¼”ã€å±±ç”°è„©ä¹Ÿ")
    
    if q:
        candidates = search_players_list(q)
        if not candidates.empty:
            candidates['label'] = candidates.apply(lambda x: f"{x['Name']} ({x['School_Name_Then']} - {x['Last_Year']}å¹´é ƒ)", axis=1)
            selected_candidate_label = st.selectbox("è©³ç´°ã‚’è¦‹ã‚‹é¸æ‰‹ã‚’é¸æŠ", candidates['label'])
            
            if selected_candidate_label:
                sel_row = candidates[candidates['label'] == selected_candidate_label].iloc[0]
                details = get_player_detail(sel_row['Name'], sel_row['School_Name_Then'])
                
                if not details.empty:
                    profile = details.iloc[-1]
                    
                    st.markdown("---")
                    st.title(f"{profile['Name']}")
                    
                    meta_info = []
                    if 'School_Name_Then' in profile: meta_info.append(f"ğŸ« {profile['School_Name_Then']}")
                    if 'Birth_Date' in profile and pd.notna(profile['Birth_Date']): meta_info.append(f"ğŸ‚ {profile['Birth_Date']}")
                    if 'Prefecture' in profile and pd.notna(profile['Prefecture']): meta_info.append(f"ğŸ“ {profile['Prefecture']}")
                    if 'Generation' in profile and pd.notna(profile['Generation']): meta_info.append(f"ğŸ“… {profile['Generation']}ä¸–ä»£")
                    st.markdown(f"<div class='profile-meta'>{'  |  '.join(meta_info)}</div>", unsafe_allow_html=True)

                    # ğŸš€ ãƒ—ãƒ­å…¥ã‚Šæƒ…å ±ï¼ˆç·‘ãƒœãƒƒã‚¯ã‚¹ï¼‰
                    if 'Pro_Team' in profile and pd.notna(profile['Pro_Team']) and profile['Pro_Team'] != '':
                        draft_info = f"{profile.get('Draft_Year', '')}å¹´"
                        rank_info = f"{profile.get('Draft_Rank', '')}ä½"
                        st.markdown(f"""
                        <div class='pro-box'>
                            ğŸš€ NPBå…¥å›£: {profile['Pro_Team']} ({draft_info} {rank_info})
                        </div>
                        """, unsafe_allow_html=True)

                    # ğŸ¥‡ ä»£è¡¨çµŒé¨“ï¼ˆé‡‘ãƒœãƒƒã‚¯ã‚¹ï¼‰- 5ã¤ã®åˆ—ã‚’ã¾ã¨ã‚ã¦è¡¨ç¤º
                    japan_cols = ['U12', 'U15', 'U18', 'U22', 'JAPAN']
                    japan_history = []
                    
                    for col in japan_cols:
                        if col in profile and pd.notna(profile[col]) and str(profile[col]).strip() != '':
                            # åˆ—åã¨å€¤ã‚’ã‚»ãƒƒãƒˆã§è¡¨ç¤ºï¼ˆä¾‹: "U18: ã‚¢ã‚¸ã‚¢é¸æ‰‹æ¨©"ï¼‰
                            # å€¤ãŒ "TRUE" ã‚„ "1" ã§ã¯ãªãã€å¤§ä¼šåãªã©ãŒå…¥ã£ã¦ã„ã‚‹ã¨æƒ³å®š
                            japan_history.append(f"{col}: {profile[col]}")
                    
                    if japan_history:
                        history_text = " / ".join(japan_history)
                        st.markdown(f"""
                        <div class='japan-box'>
                            ğŸ‡¯ğŸ‡µ ä»£è¡¨çµŒæ­´: {history_text}
                        </div>
                        """, unsafe_allow_html=True)

                    # ğŸŸ ç”²å­åœ’æˆç¸¾
                    st.subheader("ğŸŸ ç”²å­åœ’ å‡ºå ´è¨˜éŒ²")
                    
                    display_cols = ['Year', 'Season', 'Grade', 'Uniform_Number', 'Position', 'Tournament_Rank']
                    if 'Throw_Bat' in details.columns: display_cols.insert(4, 'Throw_Bat')
                    
                    valid_cols = [c for c in display_cols if c in details.columns]
                    st.dataframe(clean_and_rename(details[valid_cols]), use_container_width=True, hide_index=True)
                else: st.error("ãƒ‡ãƒ¼ã‚¿ãªã—")
        else: st.warning("è©²å½“ãªã—")

# === ãƒ¢ãƒ¼ãƒ‰3: é«˜æ ¡æ¤œç´¢ ===
elif search_mode == "ğŸ« é«˜æ ¡åã‹ã‚‰æ¢ã™":
    st.subheader("ğŸ« é«˜æ ¡æ¤œç´¢")
    q = st.text_input("é«˜æ ¡åã‚’å…¥åŠ›", key="school_q")
    
    if q:
        res = search_schools(q)
        if not res.empty:
            res['label'] = res.apply(lambda x: f"{x['School_Name_Now']} ({x['Prefecture']})", axis=1)
            school_select = st.selectbox("é«˜æ ¡ã‚’é¸æŠ", res['label'].unique())
            
            sid = res[res['label'] == school_select].iloc[0]['School_ID']
            st.divider()
            st.markdown(f"### ğŸ“œ {school_select} ã®æˆç¸¾")
            history_df = get_school_history_all(sid)
            st.dataframe(clean_and_rename(history_df), use_container_width=True, hide_index=True)
        else: st.warning("è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
