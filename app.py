import streamlit as st
from google.cloud import bigquery
from google.api_core.exceptions import NotFound
import pandas as pd
import google.oauth2.service_account

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ç”²å­åœ’DB", layout="wide", page_icon="âš¾")
st.title("âš¾ï¸ ç”²å­åœ’DB")

# --- ãƒ‡ã‚¶ã‚¤ãƒ³CSS ---
st.markdown("""
<style>
    /* ãƒ—ãƒ­å…¥ã‚Šæƒ…å ±ï¼šè½ã¡ç€ã„ãŸã‚°ãƒªãƒ¼ãƒ³ */
    .pro-box {
        padding: 15px; border-radius: 8px; 
        background-color: #2F5C45; 
        color: white;
        margin-bottom: 10px; font-weight: bold; border: 1px solid #448060;
    }
    /* ä»£è¡¨çµŒæ­´ï¼šä¾ã‚¸ãƒ£ãƒ‘ãƒ³ãƒã‚¤ãƒ“ãƒ¼ Ã— ã‚´ãƒ¼ãƒ«ãƒ‰æ–‡å­— */
    .japan-box {
        padding: 15px; border-radius: 8px; 
        background-color: #0F1C3F; 
        color: #D4AF37; 
        margin-bottom: 10px; font-weight: bold; 
        border: 1px solid #D4AF37;
    }
    /* ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è©³ç´°ï¼šèª­ã¿ã‚„ã™ã„æ˜ã‚‹ã„ã‚°ãƒ¬ãƒ¼ */
    .profile-meta {
        color: #dddddd !important; 
        font-size: 1.0em; 
        margin-bottom: 20px;
    }
    /* é¸æ‰‹åã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .player-name-title {
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 5px;
    }
    .player-kana {
        font-size: 0.55em;
        color: #bbbbbb;
        margin-left: 12px;
        font-weight: normal;
    }
    /* ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆå¤ªå­— */
    div[data-testid="stLinkButton"] p { font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- 1. BigQueryæ¥ç¶šè¨­å®š ---
@st.cache_resource
def get_bq_client():
    try:
        scopes = [
            "https://www.googleapis.com/auth/bigquery",
            "https://www.googleapis.com/auth/drive",
            "https://www.googleapis.com/auth/spreadsheets",
        ]
        credentials = google.oauth2.service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=scopes
        )
        return bigquery.Client(credentials=credentials, project=credentials.project_id)
    except Exception as e:
        st.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

client = get_bq_client()
PROJECT_ID = st.secrets["gcp_service_account"]["project_id"]
RAW_DATASET_ID = "koshien_data"
APP_DATASET_ID = "koshien_app"

# --- 2. ãƒ‡ãƒ¼ã‚¿åŒæœŸæ©Ÿèƒ½ï¼ˆå¼·åŠ›ç‰ˆï¼‰ ---
def sync_data():
    status_text = st.empty()
    bar = st.progress(0)
    dataset_ref = client.dataset(APP_DATASET_ID)
    try:
        client.get_dataset(dataset_ref)
    except NotFound:
        dataset = bigquery.Dataset(dataset_ref)
        dataset.location = "US"
        client.create_dataset(dataset)

    tables = ["m_tournament", "m_school", "m_player", "t_results", "t_scores", "m_region"]
    for i, table_name in enumerate(tables):
        status_text.text(f"åŒæœŸä¸­ï¼š {table_name}...")
        
        # â˜…ã“ã“ãŒé‡è¦ï¼šå¤ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¸€åº¦å‰Šé™¤ã—ã¦ã€åˆ—ã®å¤‰æ›´ã‚’ç¢ºå®Ÿã«åæ˜ ã•ã›ã‚‹
        client.delete_table(f"{PROJECT_ID}.{APP_DATASET_ID}.{table_name}", not_found_ok=True)
        
        query = f"CREATE OR REPLACE TABLE `{PROJECT_ID}.{APP_DATASET_ID}.{table_name}` AS SELECT * FROM `{PROJECT_ID}.{RAW_DATASET_ID}.{table_name}`"
        client.query(query).result()
        bar.progress((i + 1) / len(tables))

    st.success("æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿æ§‹æˆã§æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    st.cache_data.clear()
    st.rerun()

# --- 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ•´å½¢é–¢æ•° ---

def clean_and_rename(df):
    if df.empty: return df
    drop_cols = ['School_ID', 'ID', 'MatchLink', 'Tournament_ID', 'Region_ID']
    df = df[[c for c in df.columns if c not in drop_cols]]
    
    # â˜…ä¿®æ­£ï¼šBirth_Dateã®æºã‚‰ãã‚’ã“ã“ã§å¸å
    # DBãŒ Birth_Date ã§ã‚‚ BirthDate ã§ã‚‚ã€ã©ã¡ã‚‰ã‚‚ 'ç”Ÿå¹´æœˆæ—¥' ã«å¤‰æ›ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
    if 'Birth_Date' in df.columns: df = df.rename(columns={'Birth_Date': 'ç”Ÿå¹´æœˆæ—¥'})
    if 'BirthDate' in df.columns: df = df.rename(columns={'BirthDate': 'ç”Ÿå¹´æœˆæ—¥'})

    rename_map = {
        'Year': 'å¹´åº¦', 'Season': 'å­£ç¯€', 'Tournament': 'å¤§ä¼šå',
        'School_Name_Now': 'ç¾åœ¨æ ¡å', 'School_Name_Then': 'å½“æ™‚ã®æ ¡å',
        'District': 'åœ°åŒº', 'Prefecture': 'éƒ½é“åºœçœŒ',
        'Uniform_Number': 'èƒŒç•ªå·', 'Name': 'æ°å', 'Name_Kana': 'ãƒ•ãƒªã‚¬ãƒŠ',
        'Position': 'å®ˆå‚™', 'Grade': 'å­¦å¹´', 'Captain': 'ä¸»å°†', 'Pro_Team': 'ãƒ—ãƒ­å…¥å›£', 
        'Draft_Year': 'ãƒ‰ãƒ©ãƒ•ãƒˆå¹´', 'Draft_Rank': 'é †ä½', 'Throw_Bat': 'æŠ•æ‰“',
        'Generation': 'ä¸–ä»£', 'Career_Path': 'é€²è·¯', 'Hometown': 'å‡ºèº«åœ°',
        'U12': 'U12ä»£è¡¨', 'U15': 'U15ä»£è¡¨', 'U18': 'U18ä»£è¡¨', 'U22': 'U22ä»£è¡¨', 'JAPAN': 'ä¾ã‚¸ãƒ£ãƒ‘ãƒ³',
        'Rank': 'æˆç¸¾', 'Win_Loss': 'å‹æ•—', 'Score': 'ã‚¹ã‚³ã‚¢', 'Opponent': 'å¯¾æˆ¦æ ¡',
        'Round': 'å›æˆ¦', 'Notes': 'å‚™è€ƒ', 'History_Label': 'å‡ºå ´å›æ•°'
    }
    return df.rename(columns=rename_map)

@st.cache_data(ttl=3600)
def get_tournaments():
    try:
        sql = "SELECT * FROM `{}.{}.m_tournament` ORDER BY SAFE_CAST(Year AS INT64) DESC, Season DESC".format(PROJECT_ID, APP_DATASET_ID)
        return client.query(sql).to_dataframe().drop_duplicates()
    except: return pd.DataFrame()

@st.cache_data(ttl=3600)
def load_tournament_details(year, season):
    job_config = bigquery.QueryJobConfig(query_parameters=[
        bigquery.ScalarQueryParameter("year", "STRING", str(year)),
        bigquery.ScalarQueryParameter("season", "STRING", str(season))
    ])
    sql_list = f"SELECT tr.District, tr.School_Name_Then, s.School_Name_Now, tr.History_Label, tr.Rank, tr.School_ID FROM `{PROJECT_ID}.{APP_DATASET_ID}.t_results` AS tr LEFT JOIN `{PROJECT_ID}.{APP_DATASET_ID}.m_school` AS s ON tr.School_ID = s.School_ID WHERE tr.Year = @year AND tr.Season = @season"
    sql_scores = f"SELECT * FROM `{PROJECT_ID}.{APP_DATASET_ID}.t_scores` WHERE Year = @year AND Season = @season"
    sql_members = f"SELECT * FROM `{PROJECT_ID}.{APP_DATASET_ID}.m_player` WHERE Year = @year AND Season = @season"
    return {
        "list": client.query(sql_list, job_config=job_config).to_dataframe().drop_duplicates(),
        "scores": client.query(sql_scores, job_config=job_config).to_dataframe().drop_duplicates(),
        "members": client.query(sql_members, job_config=job_config).to_dataframe().drop_duplicates()
    }

@st.cache_data(ttl=3600)
def search_players_list(query_text):
    # â˜…ä¿®æ­£ï¼šGenerationåˆ—ãŒã¾ã åŒæœŸã•ã‚Œã¦ã„ãªã„å ´åˆã«å‚™ãˆãŸå®‰å…¨ç­–
    # ã¾ãšGenerationã‚’å«ã‚ã¦å•ã„åˆã‚ã›ã¦ã¿ã‚‹
    sql = f"""
    SELECT Name, MAX(Name_Kana) as Name_Kana, School_Name_Then, MAX(Year) as Last_Year, MAX(Generation) as Generation
    FROM `{PROJECT_ID}.{APP_DATASET_ID}.m_player`
    WHERE Name LIKE @q
    GROUP BY Name, School_Name_Then
    ORDER BY Last_Year DESC
    LIMIT 50
    """
    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter("q", "STRING", f"%{query_text}%")])
    
    try:
        return client.query(sql, job_config=job_config).to_dataframe()
    except Exception:
        # ã‚¨ãƒ©ãƒ¼ï¼ˆåˆ—ãŒãªã„ãªã©ï¼‰ãŒå‡ºãŸã‚‰ã€Generationãªã—ã§å†ãƒˆãƒ©ã‚¤
        sql_fallback = f"""
        SELECT Name, MAX(Name_Kana) as Name_Kana, School_Name_Then, MAX(Year) as Last_Year
        FROM `{PROJECT_ID}.{APP_DATASET_ID}.m_player`
        WHERE Name LIKE @q
        GROUP BY Name, School_Name_Then
        ORDER BY Last_Year DESC
        LIMIT 50
        """
        return client.query(sql_fallback, job_config=job_config).to_dataframe()

@st.cache_data(ttl=3600)
def get_player_detail(name, school_then):
    sql = f"SELECT p.*, tr.Rank as Tournament_Rank FROM `{PROJECT_ID}.{APP_DATASET_ID}.m_player` AS p LEFT JOIN `{PROJECT_ID}.{APP_DATASET_ID}.t_results` AS tr ON p.School_ID = tr.School_ID AND p.Year = tr.Year AND p.Season = tr.Season WHERE p.Name = @name AND p.School_Name_Then = @school_then ORDER BY SAFE_CAST(p.Year AS INT64), p.Season"
    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter("name", "STRING", name), bigquery.ScalarQueryParameter("school_then", "STRING", school_then)])
    return client.query(sql, job_config=job_config).to_dataframe()

@st.cache_data(ttl=3600)
def search_schools(query_text):
    sql = f"SELECT DISTINCT School_ID, School_Name_Now, Prefecture, School_Name_Then FROM `{PROJECT_ID}.{APP_DATASET_ID}.m_school` WHERE School_Name_Now LIKE @q OR School_Name_Then LIKE @q LIMIT 50"
    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter("q", "STRING", f"%{query_text}%")])
    return client.query(sql, job_config=job_config).to_dataframe()

@st.cache_data(ttl=3600)
def get_school_history_all(school_id):
    sql = f"SELECT Year, Season, Tournament, School_Name_Then, Rank FROM `{PROJECT_ID}.{APP_DATASET_ID}.t_results` WHERE School_ID = @school_id ORDER BY SAFE_CAST(Year AS INT64) DESC"
    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter("school_id", "STRING", school_id)])
    return client.query(sql, job_config=job_config).to_dataframe()

# --- 4. UIæ§‹ç¯‰ ---

st.sidebar.header("ğŸ” æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰")
search_mode = st.sidebar.radio("", ["ğŸŸ å¤§ä¼šã‹ã‚‰æ¢ã™", "ğŸ‘¤ é¸æ‰‹åã‹ã‚‰æ¢ã™", "ğŸ« é«˜æ ¡åã‹ã‚‰æ¢ã™"])
st.sidebar.markdown("---")
st.sidebar.caption("â€»åˆ—ã®è¿½åŠ ãƒ»å¤‰æ›´å¾Œã¯å¿…ãšæ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
if st.sidebar.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æœ€æ–°ã«æ›´æ–°"):
    with st.spinner("åŒæœŸä¸­..."): sync_data()

# === ãƒ¢ãƒ¼ãƒ‰1ï¼š å¤§ä¼šæ¤œç´¢ ===
if search_mode == "ğŸŸ å¤§ä¼šã‹ã‚‰æ¢ã™":
    df_tourney = get_tournaments()
    if df_tourney.empty:
        st.info("å·¦ä¸‹ã®æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        st.stop()
    df_tourney = df_tourney.fillna('')
    tourney_map = {f"{r['Year']} {r['Season']} ï¼ {r['Tournament']}": {"year": r['Year'], "season": r['Season'], "name": r['Tournament'], "l1": r.get('Year_Link',''), "l2": r.get('History_Link',''), "l3": r.get('Virtual_Koshien_Link','')} for _, r in df_tourney.iterrows()}
    
    selected_label = st.sidebar.selectbox("å¤§ä¼šã‚’é¸æŠ", list(tourney_map.keys()))
    sel = tourney_map[selected_label]
    st.header(selected_label)
    
    links = [("ğŸ”— çµ„ã¿åˆã‚ã›è¡¨", sel["l1"]), ("ğŸ› ç”²å­åœ’æ­´å²é¤¨", sel["l2"]), ("ğŸ“º ãƒãƒ¼ãƒãƒ£ãƒ«é«˜æ ¡é‡çƒ", sel["l3"])]
    valid_links = [(t, u) for t, u in links if u and str(u).startswith("http")]
    if valid_links:
        cols = st.columns(len(valid_links))
        for i, (t, u) in enumerate(valid_links): cols[i].link_button(t, u)
    
    st.divider()
    with st.spinner("ãƒ‡ãƒ¼ã‚¿å±•é–‹ä¸­..."):
        data = load_tournament_details(sel["year"], sel["season"])
        df_list = data["list"]

    if not df_list.empty:
        st.dataframe(clean_and_rename(df_list), use_container_width=True, hide_index=True)
        st.subheader("ğŸ”½ è©³ç´°ãƒ‡ãƒ¼ã‚¿é–²è¦§")
        school_opts = dict(zip(df_list['School_Name_Then'], df_list['School_ID']))
        selected_school = st.selectbox("é«˜æ ¡ã‚’é¸æŠã—ã¦ãã ã•ã„", list(school_opts.keys()))
        if selected_school:
            sid = school_opts[selected_school]
            t1, t2 = st.tabs(["âš¾ï¸ æˆ¦ç¸¾ãƒ»ã‚¹ã‚³ã‚¢", "ğŸ‘¥ ç™»éŒ²ãƒ¡ãƒ³ãƒãƒ¼"])
            with t1:
                df_s = data["scores"][data["scores"]['School_ID'] == sid]
                if not df_s.empty: st.dataframe(clean_and_rename(df_s[['Round', 'Opponent', 'Win_Loss', 'Score', 'Notes']]), use_container_width=True, hide_index=True)
                else: st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
            with t2:
                df_m = data["members"][data["members"]['School_ID'] == sid]
                if not df_m.empty:
                    df_m = df_m.sort_values('Uniform_Number', key=lambda x: pd.to_numeric(x, errors='coerce'))
                    st.dataframe(clean_and_rename(df_m[['Uniform_Number', 'Position', 'Name', 'Name_Kana', 'Grade', 'Captain', 'Pro_Team']]), use_container_width=True, hide_index=True)
                else: st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")

# === ãƒ¢ãƒ¼ãƒ‰2ï¼š é¸æ‰‹æ¤œç´¢ ===
elif search_mode == "ğŸ‘¤ é¸æ‰‹åã‹ã‚‰æ¢ã™":
    st.subheader("ğŸ‘¤ é¸æ‰‹æ¤œç´¢")
    q = st.text_input("é¸æ‰‹åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šæ¾å‚å¤§è¼”ã€å®®ä¸‹æœé™½")
    if q:
        candidates = search_players_list(q)
        if not candidates.empty:
            # GenerationãŒã‚ã‚Œã°è¡¨ç¤ºã€ãªã‘ã‚Œã°Last_Yearã‚’è¡¨ç¤ºï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
            candidates['label'] = candidates.apply(lambda r: f"{r['Name']} ï¼ˆ{r['School_Name_Then']} ï¼ {r['Generation'] if 'Generation' in r and pd.notna(r['Generation']) else r['Last_Year']}ä¸–ä»£ï¼‰", axis=1)
            selected_candidate_label = st.selectbox("è©³ç´°ã‚’è¦‹ã‚‹é¸æ‰‹ã‚’é¸æŠ", candidates['label'])
            if selected_candidate_label:
                sel_row = candidates[candidates['label'] == selected_candidate_label].iloc[0]
                details = get_player_detail(sel_row['Name'], sel_row['School_Name_Then'])
                if not details.empty:
                    profile = details.iloc[-1]
                    kana = f"ï¼ˆ{profile['Name_Kana']}ï¼‰" if pd.notna(profile.get('Name_Kana')) else ""
                    st.markdown(f"<div class='player-name-title'>{profile['Name']}<span class='player-kana'>{kana}</span></div>", unsafe_allow_html=True)
                    
                    meta = []
                    if 'School_Name_Then' in profile: meta.append(f"ğŸ« {profile['School_Name_Then']}")
                    
                    # â˜…ä¿®æ­£ï¼šBirth_Dateã¨BirthDateã®ä¸¡æ–¹ã«å¯¾å¿œ
                    bday = profile.get('Birth_Date') or profile.get('BirthDate')
                    if pd.notna(bday): meta.append(f"ğŸ‚ {bday}ç”Ÿ")
                    
                    if pd.notna(profile.get('Hometown')): meta.append(f"ğŸ“ {profile['Hometown']}å‡ºèº«")
                    if pd.notna(profile.get('Generation')): meta.append(f"ğŸ“… {profile['Generation']}ä¸–ä»£")
                    if pd.notna(profile.get('Career_Path')): meta.append(f"ğŸ‘£ é€²è·¯ï¼š {profile['Career_Path']}")
                    st.markdown(f"<div class='profile-meta'>{'ã€€|ã€€'.join(meta)}</div>", unsafe_allow_html=True)

                    if pd.notna(profile.get('Pro_Team')) and profile['Pro_Team'] != '':
                        st.markdown(f"<div class='pro-box'>ğŸš€ NPBå…¥å›£ï¼š {profile['Pro_Team']} ï¼ˆ{profile.get('Draft_Year','')}å¹´ {profile.get('Draft_Rank','')}ä½ï¼‰</div>", unsafe_allow_html=True)

                    japan_h = [f"{c}ï¼š {profile[c]}" for c in ['U12', 'U15', 'U18', 'U22', 'JAPAN'] if pd.notna(profile.get(c)) and str(profile[c]).strip() != '']
                    if japan_h: st.markdown(f"<div class='japan-box'>ğŸ‡¯ğŸ‡µ ä»£è¡¨çµŒæ­´ï¼š {' ï¼ '.join(japan_h)}</div>", unsafe_allow_html=True)

                    st.subheader("ğŸŸ ç”²å­åœ’ å‡ºå ´è¨˜éŒ²")
                    cols = ['Year', 'Season', 'Grade', 'Uniform_Number', 'Position', 'Throw_Bat', 'Tournament_Rank']
                    st.dataframe(clean_and_rename(details[[c for c in cols if c in details.columns]]), use_container_width=True, hide_index=True)
                else: st.error("ãƒ‡ãƒ¼ã‚¿ãªã—")
        else: st.warning("è©²å½“ãªã—")

# === ãƒ¢ãƒ¼ãƒ‰3ï¼š é«˜æ ¡æ¤œç´¢ ===
elif search_mode == "ğŸ« é«˜æ ¡åã‹ã‚‰æ¢ã™":
    st.subheader("ğŸ« é«˜æ ¡æ¤œç´¢")
    q = st.text_input("é«˜æ ¡åã‚’å…¥åŠ›")
    if q:
        res = search_schools(q)
        if not res.empty:
            res['label'] = res.apply(lambda x: f"{x['School_Name_Now']} ï¼ˆ{x['Prefecture']}ï¼‰", axis=1)
            school_select = st.selectbox("é«˜æ ¡ã‚’é¸æŠ", res['label'].unique())
            sid = res[res['label'] == school_select].iloc[0]['School_ID']
            st.divider()
            st.markdown(f"### ğŸ“œ {school_select} ã®æˆç¸¾")
            st.dataframe(clean_and_rename(get_school_history_all(sid)), use_container_width=True, hide_index=True)
